{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "DATA_Crawl2.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/enebin/StockExchange/blob/master/CRAWL_NOTE/DATA_Crawl2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LD2TAO8FBsyN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "b9c7d322-aff8-4782-e5e9-99f6b3d522e2"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive/')\n",
        "\n",
        "% pip install bcolors\n",
        "\n",
        "# coding = utf-8-sig\n",
        "import os.path\n",
        "import time\n",
        "import bcolors\n",
        "import pandas as pd\n",
        "import pandas_datareader.data as web\n",
        "import multiprocessing as mp\n",
        "import logging\n",
        "\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "from urllib.request import urlopen\n",
        "from urllib.error import HTTPError\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "# 콤마를 숫자에서 지워주는 편의성을 위한 함수입니다. 반환값은 float 형 입니다.\n",
        "def remove_coma(input_no):\n",
        "    try:\n",
        "        return float(input_no.replace(',', ''))\n",
        "    except ValueError:\n",
        "        return float(input_no)\n",
        "\n",
        "\n",
        "# 리스트를 일정한 크기로 분할하여줍니다. 멀티프로세싱의 프로세스 배열 슬라이싱을 위해 사용합니다.\n",
        "def chunks(input_list, size):\n",
        "    for element in range(0, len(input_list), size):\n",
        "        yield input_list[element: element + size]\n",
        "\n",
        "\n",
        "# 종목 등락률을 계산합니다.\n",
        "def get_FR(cur, prev):\n",
        "    fr = ((cur - prev) / prev) * 100\n",
        "    fr = round(fr, 2)\n",
        "    return fr\n",
        "\n",
        "\n",
        "# 종목 코드 리스트를 가져온 후 전처리합니다. init 함수에서 클래스 생성과 함께 실행됩니다.\n",
        "def get_code_list(market, m_type, in_path):\n",
        "    print(bcolors.WAITMSG + \"Data processing for \" + market + '_' + m_type + \" starts now!\" + bcolors.ENDC)\n",
        "\n",
        "    df = pd.read_csv(in_path)\n",
        "    df.CODE = df.CODE.map('{:06d}'.format)\n",
        "\n",
        "    code_list = df.CODE.tolist()\n",
        "\n",
        "    return code_list\n",
        "\n",
        "\n",
        "# 쓰레딩을 위해 사용하는 스타트 함수입니다.\n",
        "def starter(input_code, glob, period):\n",
        "    if period == 'week':\n",
        "        name, value_tag = get_data(input_code)\n",
        "\n",
        "        # 에러상황(ETF, 리츠 등 펀드류 코드 경우)시 리턴합니다.\n",
        "        if name == -1:\n",
        "            logging.warning(input_code)\n",
        "            return\n",
        "        else:\n",
        "            temp_row = make_data_frame(name, input_code, value_tag)\n",
        "            glob.df = glob.df.append(temp_row)\n",
        "\n",
        "    elif period == 'day':\n",
        "        curPrice, prevPrice = get_price(input_code)\n",
        "        temp_row = make_price_frame(input_code, curPrice, prevPrice)\n",
        "        glob.df = glob.df.append(temp_row)\n",
        "\n",
        "    elif period == 'all':\n",
        "        name, curPrice, prevPrice, value_tag = get_all(input_code)\n",
        "\n",
        "        # 에러상황(ETF, 리츠 등 펀드류 코드 경우)시 리턴합니다.\n",
        "        if name == -1:\n",
        "            logging.warning(input_code)\n",
        "            return\n",
        "        else:\n",
        "            temp_row = make_all_frame(name, input_code, curPrice, prevPrice, value_tag)\n",
        "            glob.df = glob.df.append(temp_row)\n",
        "\n",
        "\n",
        "# 종목코드 하나를 받아 투자지표를 크롤링합니다. [종목명, [투자지표]]를 반환합니다.\n",
        "\n",
        "\n",
        "def get_data(input_code):\n",
        "    # 종목코드를 가져와 NAVER 증권 정보 URL에 대입합니다.\n",
        "    url = \"https://finance.naver.com/item/main.nhn?code=\" + input_code\n",
        "\n",
        "    # BS4를 이용한 HTML 소스 크롤링입니다.\n",
        "    url_result = urlopen(url)\n",
        "    html = url_result.read()\n",
        "    soup = BeautifulSoup(html, 'lxml')\n",
        "\n",
        "    # 잘못된 코드나 ETF를 솎아내기 위해 예외처리를 하였습니다.\n",
        "    try:\n",
        "        # HTML 소스에서 회사명을 찾아 저장합니다.\n",
        "        name = soup.find(\"div\", {\"class\": \"wrap_company\"}).find(\"h2\").text\n",
        "\n",
        "        # HTML 소스에서 투자지표 Table을 찾아 저장한 후 값을 추출합니다.\n",
        "        table_tag = soup.find(\"table\", {\"class\": \"per_table\"})\n",
        "        values_raw = table_tag.find_all(\"em\")\n",
        "\n",
        "        return name, values_raw\n",
        "\n",
        "    except AttributeError:\n",
        "        print(bcolors.ERRMSG + \"ERROR OCCURS\\n\" + bcolors.ITALIC +\n",
        "              \"Possible Error: It can be ETF, REITs, etc...\")\n",
        "        logging.warning(input_code)\n",
        "        return -1, [-1]\n",
        "\n",
        "\n",
        "# 종목코드 하나를 받아 주가를 받아옵니다. [현재가, 전일종가]를 반환합니다.\n",
        "def get_price(input_code, try_cnt=1):\n",
        "    \"\"\"\n",
        "    # 야후 파이낸스릉 이용한 방법. 없는 데이터가 너무 많다.\n",
        "    if market == 'KOSPI':\n",
        "        code_mod = code + '.KS'\n",
        "    elif market == 'TEST':\n",
        "        code_mod = code + '.KS'\n",
        "    else:\n",
        "        code_mod = code + '.KQ'\n",
        "\n",
        "    today = datetime.today().strftime('%Y-%m-%d')\n",
        "\n",
        "    try:\n",
        "        prices = web.DataReader(code_mod, \"yahoo\", today)\n",
        "        print(\"url opened\")\n",
        "        curPrice = prices.Close.iloc[0]\n",
        "        prevPrice = prices.Open.iloc[0]\n",
        "    except KeyError:\n",
        "        print(code_mod)\n",
        "    \"\"\"\n",
        "\n",
        "    \"\"\"\n",
        "    # KRX 한국 거래소를 이용한 방법. 빠를땐 광속이나 대부분 더럽게 느리다. \n",
        "    url = \"http://asp1.krx.co.kr/servlet/krx.asp.XMLSiseEng?code={}\".format(code)\n",
        "    req = urlopen(url)\n",
        "    print(\"url opened\")\n",
        "    result = req.read()\n",
        "    xmlsoup = BeautifulSoup(result, \"lxml-xml\")\n",
        "    curPrice = xmlsoup.find(\"TBL_StockInfo\").attrs[\"CurJuka\"]\n",
        "    prevPrice = xmlsoup.find(\"TBL_StockInfo\").attrs[\"PrevJuka\"]\n",
        "\n",
        "    curPrice = remove_coma(curPrice)\n",
        "    prevPrice = remove_coma(prevPrice)\n",
        "    \"\"\"\n",
        "\n",
        "    # 네이버 금융을 이용한 방법. 그나마 가장 안정적이고 준수하다.\n",
        "    # 소스에서 현재가를 찾아 저장합니다. (주로 크롤링한 날 종가)\n",
        "    url = \"https://finance.naver.com/item/main.nhn?code=\" + input_code\n",
        "\n",
        "    # BS4를 이용한 HTML 소스 크롤링입니다.\n",
        "    url_result = urlopen(url)\n",
        "    html = url_result.read()\n",
        "    soup = BeautifulSoup(html, 'lxml')\n",
        "\n",
        "    try:\n",
        "        # 소스에서 현재가를 찾아 저장합니다. (주로 크롤링한 날 종가)\n",
        "        curPrice = soup.find(\"p\", {\"class\": \"no_today\"}).text\n",
        "        curPrice = remove_coma(curPrice.split('\\n')[2])\n",
        "\n",
        "        prevPrice = soup.find(\"td\", {\"class\": \"first\"}).text\n",
        "        prevPrice = remove_coma(prevPrice.split('\\n')[3])\n",
        "\n",
        "    except AttributeError:\n",
        "        print(bcolors.ERRMSG + \"ERROR OCCURS\\n\" + bcolors.ITALIC +\n",
        "              \"Possible Error: It can be transaction suspension, delisting, etc...\")\n",
        "\n",
        "    return curPrice, prevPrice\n",
        "\n",
        "\n",
        "# 주가와 지표 모두 받아옵니다.\n",
        "def get_all(input_code):\n",
        "    # 종목코드를 가져와 NAVER 증권 정보 URL에 대입합니다.\n",
        "    url = \"https://finance.naver.com/item/main.nhn?code=\" + input_code\n",
        "\n",
        "    # BS4를 이용한 HTML 소스 크롤링입니다.\n",
        "    url_result = urlopen(url)\n",
        "    html = url_result.read()\n",
        "    soup = BeautifulSoup(html, 'lxml')\n",
        "\n",
        "    # 잘못된 코드나 ETF를 솎아내기 위해 예외처리를 하였습니다.\n",
        "    try:\n",
        "        # HTML 소스에서 회사명을 찾아 저장합니다.\n",
        "        name = soup.find(\"div\", {\"class\": \"wrap_company\"}).find(\"h2\").text\n",
        "\n",
        "        # HTML 소스에서 투자지표 Table을 찾아 저장한 후 값을 추출합니다.\n",
        "        table_tag = soup.find(\"table\", {\"class\": \"per_table\"})\n",
        "        values_raw = table_tag.find_all(\"em\")\n",
        "\n",
        "        # 소스에서 현재가를 찾아 저장합니다. (주로 크롤링한 날 종가)\n",
        "        curPrice = soup.find(\"p\", {\"class\": \"no_today\"}).text\n",
        "        curPrice = remove_coma(curPrice.split('\\n')[2])\n",
        "\n",
        "        prevPrice = soup.find(\"td\", {\"class\": \"first\"}).text\n",
        "        prevPrice = remove_coma(prevPrice.split('\\n')[3])\n",
        "\n",
        "        return name, curPrice, prevPrice, values_raw\n",
        "\n",
        "    except AttributeError:\n",
        "        print(bcolors.ERRMSG + \"ERROR OCCURS\\n\" + bcolors.ITALIC +\n",
        "              \"Possible Error: It can be REITs, Transaction Suspension etc...\")\n",
        "        logging.warning(input_code)\n",
        "        return -1, -1, -1, [-1]\n",
        "\n",
        "\n",
        "# get_data 에서 크롤링한 데이터를 받아 데이터프레임에 저장하는 함수입니다.\n",
        "# 데이터프레임을 반환합니다.\n",
        "def make_data_frame(name, input_code, values_raw):\n",
        "    # 크롤링으로 받은 HTML 소스(values_raw)에서 PER, PBR 등의 값을 추출합니다.\n",
        "    values = []\n",
        "    for i in values_raw:\n",
        "        content = i.text\n",
        "        if content == 'N/A':\n",
        "            values.append('N/A')\n",
        "        else:\n",
        "            values.append(remove_coma(content))\n",
        "\n",
        "    # 1줄짜리 임시 데이터프레임을 구성하여 데이터를 저장합니다.\n",
        "    temp_data = pd.DataFrame(columns=(\"NAME\", \"CODE\", 'CUR PRICE', 'PREV PRICE', 'FR',\n",
        "                                      \"PER\", \"EPS\", \"E_PER\", \"E_EPS\", \"PBR\", \"BPS\", \"ITR\"))\n",
        "\n",
        "    temp_data.loc[0, 'NAME'] = name\n",
        "    temp_data.loc[0, 'CODE'] = input_code\n",
        "    temp_data.loc[0, 'PER':\"ITR\"] = values\n",
        "\n",
        "    # 진행상황을 체크하며 값을 확인합니다.\n",
        "    # print(temp_data.tail(1))\n",
        "\n",
        "    # 데이터프레임을 반환합니다.\n",
        "    return temp_data\n",
        "\n",
        "\n",
        "# 종목코드를 받아 주식의 현재가, 전일 종가, 등락률을 저장하는 함수입니다.\n",
        "# 데이터프레임을 반환합니다.\n",
        "def make_price_frame(input_code, curPrice, prevPrice):\n",
        "    temp_data = pd.DataFrame(columns=['CODE', 'CUR PRICE', 'PREV PRICE', 'FR'])\n",
        "\n",
        "    temp_data.loc[0, 'CODE'] = input_code\n",
        "    temp_data.loc[0, 'CUR PRICE'] = curPrice\n",
        "    temp_data.loc[0, 'PREV PRICE'] = prevPrice\n",
        "    temp_data.loc[0, 'FR'] = float(get_FR(curPrice, prevPrice))\n",
        "\n",
        "    # 진행상황을 체크하며 값을 확인합니다.\n",
        "    # print(res.head())\n",
        "\n",
        "    return temp_data\n",
        "\n",
        "\n",
        "def make_all_frame(name, input_code, curPrice, prevPrice, values_raw):\n",
        "    # 크롤링으로 받은 HTML 소스(values_raw)에서 PER, PBR 등의 값을 추출합니다.\n",
        "    values = []\n",
        "    for i in values_raw:\n",
        "        content = i.text\n",
        "        if content == 'N/A':\n",
        "            values.append('N/A')\n",
        "        else:\n",
        "            values.append(remove_coma(content))\n",
        "\n",
        "    # 1줄짜리 임시 데이터프레임을 구성하여 데이터를 저장합니다.\n",
        "    temp_data = pd.DataFrame(columns=(\"NAME\", \"CODE\", 'CUR PRICE', 'PREV PRICE', 'FR',\n",
        "                                      \"PER\", \"EPS\", \"E_PER\", \"E_EPS\", \"PBR\", \"BPS\", \"ITR\"))\n",
        "\n",
        "    temp_data.loc[0, 'NAME'] = name\n",
        "    temp_data.loc[0, 'CODE'] = input_code\n",
        "    temp_data.loc[0, 'PER':\"ITR\"] = values\n",
        "    temp_data.loc[0, 'CODE'] = input_code\n",
        "    temp_data.loc[0, 'CUR PRICE'] = curPrice\n",
        "    temp_data.loc[0, 'PREV PRICE'] = prevPrice\n",
        "\n",
        "    # 진행상황을 체크하며 값을 확인합니다.\n",
        "    # print(temp_data.tail(1))\n",
        "\n",
        "    # 데이터프레임을 반환합니다.\n",
        "    return temp_data\n",
        "\n",
        "\n",
        "# 프로그램이 끝났다면 CSV 파일로 저장한 후 종료합니다.\n",
        "def merger(globs, code_list, period, in_path, out_path):\n",
        "    result = measurements\n",
        "    for glob in globs:\n",
        "        result = result.append(glob.df)\n",
        "\n",
        "    print(bcolors.OKMSG + \"Finished! %d items were collected, except for %d errors\"\n",
        "          % (result.shape[0], len(code_list) - result.shape[0]))\n",
        "\n",
        "    # 결과데이터를 csv 로 출력하기 위한 과정입니다.\n",
        "    print(bcolors.WAITMSG + \"Now processing output... \" + bcolors.ENDC)\n",
        "    result.drop(['NAME'], axis='columns', inplace=True)\n",
        "\n",
        "    original_df = pd.read_csv(in_path)\n",
        "    original_df.CODE = original_df.CODE.map('{:06d}'.format)\n",
        "\n",
        "    result = pd.merge(original_df, result, on='CODE')\n",
        "    file_name = out_path\n",
        "\n",
        "    if os.path.isfile(file_name):\n",
        "        object_df = pd.read_csv(file_name)\n",
        "\n",
        "        if period == 'day':\n",
        "            result.iloc[:, 10:16] = object_df.iloc[:, 10:16]\n",
        "        elif period == 'week':\n",
        "            result.loc[:, 'CUR PRICE'] = object_df.loc[:, 'CUR PRICE']\n",
        "            result.loc[:, 'PREV PRICE'] = object_df.loc[:, 'PREV PRICE']\n",
        "        elif period == 'all':\n",
        "            result.loc[:, 'PER':\"ITR\"] = object_df.loc[:, 'PER':\"ITR\"]\n",
        "            result.loc[:, 'CUR PRICE'] = object_df.loc[:, 'CUR PRICE']\n",
        "            result.loc[:, 'PREV PRICE'] = object_df.loc[:, 'PREV PRICE']\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "    result = result.fillna('N/A')\n",
        "    print(bcolors.HELP + \"↓ Information about results is here ↓\" + bcolors.ENDC)\n",
        "    print(result.info())\n",
        "\n",
        "    result.to_csv(file_name, encoding='utf-8-sig', index=False)\n",
        "    print(bcolors.OKMSG + \"Done Successfully!\" + bcolors.ENDC)\n",
        "    print('\\n')\n",
        "\n",
        "\n",
        "def multiprocess(globs, period, code_list, in_path, out_path, numberOfThreads=8):\n",
        "    # 값들을 저장할 Pandas 데이터프레임을 구성합니다.\n",
        "    # Multiprocessing 을 위한 전처리도 같이 합니다.\n",
        "    # 프로세스의 개수 (MAX = 18)\n",
        "    if numberOfThreads > 18:\n",
        "        print(bcolors.ERRMSG + \"Too much process. Check number of threads again\")\n",
        "        return\n",
        "\n",
        "    if period == 'week':\n",
        "        print(bcolors.OKMSG + \"Processing type is: Investment index.\")\n",
        "    else:\n",
        "        print(bcolors.OKMSG + \"Processing type is: Price informations.\")\n",
        "\n",
        "    for glob in globs:\n",
        "        glob.df = measurements\n",
        "\n",
        "    # 데이터프레임을 프로세스 개수에 따라 분배하며 프로세스 개수는 성능 여유분에 따라 조절 가능합니다.\n",
        "    processes = []\n",
        "    index = 0\n",
        "    for code in tqdm(code_list, desc=\"Processing DATA\"):\n",
        "        process = mp.Process(target=starter, args=(str(code), globs[index], str(period)))\n",
        "        index = (index + 1) % numberOfThreads\n",
        "        processes.append(process)\n",
        "\n",
        "    print(bcolors.OKMSG + \"Done Successfully\" + bcolors.ENDC)\n",
        "    print(bcolors.OKMSG + \"Number of processes: \" + str(numberOfThreads) + bcolors.ENDC)\n",
        "    print(bcolors.WAITMSG + \"Analysis starts now. \" + bcolors.ITALIC +\n",
        "          \"FYI: Only stocks are included\" + bcolors.ENDC)\n",
        "\n",
        "    for i in chunks(processes, numberOfThreads):\n",
        "        for j in i:\n",
        "            j.start()\n",
        "        for j in i:\n",
        "            j.join()\n",
        "\n",
        "        # 진행상황을 체크하며 값을 확인합니다.\n",
        "        count = 0\n",
        "        for glob in globs:\n",
        "            count += glob.df.shape[0]\n",
        "        tqdm(total=len(code_list)).update(count)\n",
        "\n",
        "        # for glob in globs:\n",
        "        #     print(glob.df.tail(1), end='\\n')\n",
        "\n",
        "    merger(globs, code_list, period, in_path, out_path)\n",
        "\n",
        "\n",
        "def initialize(input_list):\n",
        "    for x in input_list:\n",
        "        x = 0\n",
        "\n",
        "\n",
        "# ========아래로 메인 코드입니다========= #\n",
        "if __name__ == '__main__':\n",
        "    start_time = time.time()\n",
        "\n",
        "    measurements = pd.DataFrame(columns=(\"NAME\", \"CODE\", 'CUR PRICE', 'PREV PRICE', 'FR', \"PER\", \"EPS\",\n",
        "                                         \"E_PER\", \"E_EPS\", \"PBR\", \"BPS\", \"ITR\"))\n",
        "\n",
        "    unit_all = [['KOSPI', 'noBank', 'all'],\n",
        "                ['KOSDAQ', 'noBank', 'all']]\n",
        "\n",
        "    price_ks = [['KOSPI', 'noBank', 'day']]\n",
        "\n",
        "    unit_test = [['TEST', 'noBank', 'all'],\n",
        "                 ['TEST2', 'noBank', 'all']]\n",
        "   \n",
        "    ks_all = [['KOSPI', 'noBank', 'all']]\n",
        "\n",
        "\n",
        "    for a in ks_all:\n",
        "        market = a[0]\n",
        "        m_type = a[1]\n",
        "        period = a[2]\n",
        "\n",
        "        in_path = '/content/gdrive/My Drive/DATA/' + market + '_' + m_type + '.csv'\n",
        "        out_path = '/content/gdrive/My Drive/DATA/Results/DATA_' + market + '_' + m_type + datetime.today().strftime(\"_%Y%m%d\") + '.csv'\n",
        "\n",
        "        # 12개의 데이터프레임을 만들어줍니다. 각각의 프로세서가 사용할 데이터프레임입니다.\n",
        "        manager = mp.Manager()\n",
        "        global1 = manager.Namespace()\n",
        "        global2 = manager.Namespace()\n",
        "        global3 = manager.Namespace()\n",
        "        global4 = manager.Namespace()\n",
        "        global5 = manager.Namespace()\n",
        "        global6 = manager.Namespace()\n",
        "        global7 = manager.Namespace()\n",
        "        global8 = manager.Namespace()\n",
        "        global9 = manager.Namespace()\n",
        "        global10 = manager.Namespace()\n",
        "        global11 = manager.Namespace()\n",
        "        global12 = manager.Namespace()\n",
        "\n",
        "        globs = [global1, global2, global3, global4, global5, global6,\n",
        "                 global7, global8, global9, global10, global11, global12]\n",
        "\n",
        "        '''===\n",
        "        market은 'KOSPI', 'KOSDAQ'중 하나를 선택합니다. 선택하지 않을 시 기본값은 'KOSPI'입니다.\n",
        "    \n",
        "        m_type은 'noBank'(지주회사, 리츠, 은행 등 금융회사 제외), 'noUse'(noBank에서 제외된 요소만), 'ALL'(제외 없이 모두 다 포함)-\n",
        "        -중 하나를 선택합니다. 선택하지 않을 시 기본값은 'noBank'입니다.\n",
        "    \n",
        "        period 는 'day'와 'week' 중 하나를 선택합니다. 'day'를 선택할 경우 가격에 관한 정보가, 'week'을 선택할 경우 투자지표에 관한 정보가 \n",
        "        수집됩니다. \n",
        "        ==='''\n",
        "\n",
        "        code_list = get_code_list(market=market, m_type=m_type, in_path=in_path)\n",
        "\n",
        "        # 멀티 프로세스는 속도 향상을 위해 필요합니다. n개의 프로세스를 사용해 속도를 n배로 끌어 올립니다.\n",
        "        # 기본값은 8입니다.\n",
        "        now = time.localtime()\n",
        "        print(bcolors.OKMSG + \"Current time: \" + bcolors.BITALIC + \"%04d/%02d/%02d %02d:%02d:%02d\" % (now.tm_year, now.tm_mon, now.tm_mday, now.tm_hour, now.tm_min, now.tm_sec) + bcolors.ENDC)\n",
        "        multiprocess(globs, period=period, code_list=code_list, in_path=in_path, out_path=out_path, numberOfThreads=8)\n",
        "\n",
        "        initialize(globs)\n",
        "        initialize(code_list)\n",
        "\n",
        "    ex_time = time.time() - start_time\n",
        "\n",
        "    print('\\n')\n",
        "    print(bcolors.OKMSG + \"It took %dm %.2fs.\" % (ex_time / 60, round(ex_time, 2) % 60) + bcolors.ENDC)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n",
            "Requirement already satisfied: bcolors in /usr/local/lib/python3.6/dist-packages (1.0.2)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}