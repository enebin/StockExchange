{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/enebin/StockExchange/blob/master/CRAWL_NOTE/Data_Crawler_Lite.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 368
    },
    "colab_type": "code",
    "id": "LD2TAO8FBsyN",
    "outputId": "ba106f99-39b0-46a1-8814-dc2e7da763f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive/\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-88c94c21873c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0min_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/gdrive/My Drive/DATA/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmarket\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mm_type\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mout_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/gdrive/My Drive/DATA/Results/DATA_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmarket\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mm_type\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoday\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_%Y%m%d\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'market' is not defined"
     ]
    }
   ],
   "source": [
    "from google.colab import drive \n",
    "drive.mount('/content/gdrive/')\n",
    "\n",
    "% pip install bcolors\n",
    "\n",
    "# coding = utf-8-sig\n",
    "import os.path\n",
    "import time\n",
    "import bcolors\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "import logging\n",
    "\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# 콤마를 숫자에서 지워주는 편의성을 위한 함수입니다. 반환값은 float 형 입니다.\n",
    "def remove_coma(input_no):\n",
    "    try:\n",
    "        return float(input_no.replace(',', ''))\n",
    "    except ValueError:\n",
    "        return float(input_no)\n",
    "\n",
    "\n",
    "# 리스트를 일정한 크기로 분할하여줍니다. 멀티프로세싱의 프로세스 배열 슬라이싱을 위해 사용합니다.\n",
    "def chunks(input_list, size):\n",
    "    for element in range(0, len(input_list), size):\n",
    "        yield input_list[element: element + size]\n",
    "\n",
    "\n",
    "def initialize(input_list):\n",
    "    for x in input_list:\n",
    "        x = 0\n",
    "\n",
    "\n",
    "# 종목 코드 리스트를 가져온 후 전처리합니다. init 함수에서 클래스 생성과 함께 실행됩니다.\n",
    "def get_code_list(market, m_type, in_path):\n",
    "    print(bcolors.WAITMSG + \"Data processing for \" + market + '_' + m_type + \" starts now!\" + bcolors.ENDC)\n",
    "\n",
    "    df = pd.read_csv(in_path)\n",
    "    df.CODE = df.CODE.map('{:06d}'.format)\n",
    "\n",
    "    code_list = df.CODE.tolist()\n",
    "\n",
    "    return code_list\n",
    "\n",
    "\n",
    "# 쓰레딩을 위해 사용하는 스타트 함수입니다.\n",
    "def starter(input_code, glob):\n",
    "    name, curPrice, prevPrice, co_per, value_tag = get_all(input_code)\n",
    "\n",
    "    # 에러상황(ETF, 리츠 등 펀드류 코드 경우)시 리턴합니다.\n",
    "    if name == -1:\n",
    "        logging.warning(input_code)\n",
    "        return\n",
    "    else:\n",
    "        temp_row = make_all_frame(name, input_code, curPrice, prevPrice, co_per, value_tag)\n",
    "        glob.df = glob.df.append(temp_row)\n",
    "\n",
    "\n",
    "# 주가와 지표 모두 받아옵니다.\n",
    "def get_all(input_code):\n",
    "    # 종목코드를 가져와 NAVER 증권 정보 URL에 대입합니다.\n",
    "    url = \"https://finance.naver.com/item/main.nhn?code=\" + input_code\n",
    "\n",
    "    # BS4를 이용한 HTML 소스 크롤링입니다.\n",
    "    url_result = urlopen(url)\n",
    "    html = url_result.read()\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "    # 잘못된 코드나 ETF를 솎아내기 위해 예외처리를 하였습니다.\n",
    "    try:\n",
    "        # HTML 소스에서 회사명을 찾아 저장합니다.\n",
    "        name = soup.find(\"div\", {\"class\": \"wrap_company\"}).find(\"h2\").text\n",
    "\n",
    "        # HTML 소스에서 투자지표 Table을 찾아 저장한 후 값을 추출합니다.\n",
    "        table_tag = soup.find(\"table\", {\"class\": \"per_table\"})\n",
    "        values_raw = table_tag.find_all(\"em\")\n",
    "\n",
    "        # 동일업종 PER을 수집합니다.\n",
    "        co_per_tag = soup.find(\"table\", {\"summary\": \"동일업종 PER 정보\"})\n",
    "        co_per = co_per_tag.find_all(\"em\")[0].text\n",
    "\n",
    "        # 소스에서 현재가를 찾아 저장합니다. (주로 크롤링한 날 종가)\n",
    "        curPrice = soup.find(\"p\", {\"class\": \"no_today\"}).text\n",
    "        curPrice = remove_coma(curPrice.split('\\n')[2])\n",
    "\n",
    "        prevPrice = soup.find(\"td\", {\"class\": \"first\"}).text\n",
    "        prevPrice = remove_coma(prevPrice.split('\\n')[3])\n",
    "\n",
    "        return name, curPrice, prevPrice, co_per, values_raw\n",
    "\n",
    "    except AttributeError:\n",
    "        print(bcolors.ERRMSG + \"ERROR OCCURS\\n\" + bcolors.ITALIC +\n",
    "              \"Possible Error: It can be REITs, Transaction Suspension etc...\")\n",
    "        logging.warning(input_code)\n",
    "        return -1, -1, -1, [-1]\n",
    "\n",
    "\n",
    "def make_all_frame(name, input_code, curPrice, prevPrice, co_per, values_raw):\n",
    "    # 크롤링으로 받은 HTML 소스(values_raw)에서 PER, PBR 등의 값을 추출합니다.\n",
    "    values = []\n",
    "    for i in values_raw:\n",
    "        content = i.text\n",
    "        if content == 'N/A':\n",
    "            values.append('N/A')\n",
    "        else:\n",
    "            values.append(remove_coma(content))\n",
    "    values.insert(1, co_per)\n",
    "\n",
    "    # 1줄짜리 임시 데이터프레임을 구성하여 데이터를 저장합니다.\n",
    "    temp_data = pd.DataFrame(columns=(\"NAME\", \"CODE\", 'CUR PRICE', 'PREV PRICE', 'FR',\n",
    "                                      \"PER\", \"CO_PER\", \"EPS\", \"E_PER\", \"E_EPS\", \"PBR\",\n",
    "                                      \"BPS\", \"ITR\"))\n",
    "\n",
    "    temp_data.loc[0, 'NAME'] = name\n",
    "    temp_data.loc[0, 'CODE'] = input_code\n",
    "    temp_data.loc[0, 'PER':\"ITR\"] = values\n",
    "    temp_data.loc[0, 'CUR PRICE'] = curPrice\n",
    "    temp_data.loc[0, 'PREV PRICE'] = prevPrice\n",
    "\n",
    "    # 진행상황을 체크하며 값을 확인합니다.\n",
    "    # print(temp_data.tail(1))\n",
    "\n",
    "    # 데이터프레임을 반환합니다.\n",
    "    return temp_data\n",
    "\n",
    "\n",
    "# 프로그램이 끝났다면 CSV 파일로 저장한 후 종료합니다.\n",
    "def merger(globs, code_list, in_path, out_path):\n",
    "    result = measurements\n",
    "    for glob in globs:\n",
    "        result = result.append(glob.df)\n",
    "\n",
    "    print(bcolors.OKMSG + \"Finished! %d items were collected, except for %d errors\"\n",
    "          % (result.shape[0], len(code_list) - result.shape[0]))\n",
    "\n",
    "    # 결과데이터를 csv 로 출력하기 위한 과정입니다.\n",
    "    print(bcolors.WAITMSG + \"Now processing output... \" + bcolors.ENDC)\n",
    "    result.drop(['NAME'], axis='columns', inplace=True)\n",
    "\n",
    "    original_df = pd.read_csv(in_path)\n",
    "    original_df.CODE = original_df.CODE.map('{:06d}'.format)\n",
    "\n",
    "    result = pd.merge(original_df, result, on='CODE')\n",
    "    file_name = out_path\n",
    "\n",
    "    if os.path.isfile(file_name):\n",
    "        object_df = pd.read_csv(file_name)\n",
    "        result.loc[:, 'PER':\"ITR\"] = object_df.loc[:, 'PER':\"ITR\"]\n",
    "        result.loc[:, 'CUR PRICE'] = object_df.loc[:, 'CUR PRICE']\n",
    "        result.loc[:, 'PREV PRICE'] = object_df.loc[:, 'PREV PRICE']\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    result = result.fillna('N/A')\n",
    "    print(bcolors.HELP + \"↓ Information about results is here ↓\" + bcolors.ENDC)\n",
    "    print(result.info())\n",
    "\n",
    "    result.to_csv(file_name, encoding='utf-8-sig', index=False)\n",
    "    print(bcolors.OKMSG + \"Done Successfully!\" + bcolors.ENDC)\n",
    "    print('\\n')\n",
    "\n",
    "\n",
    "def multiprocess(globs, code_list, in_path, out_path, numberOfThreads=8):\n",
    "    # 값들을 저장할 Pandas 데이터프레임을 구성합니다.\n",
    "    # Multiprocessing 을 위한 전처리도 같이 합니다.\n",
    "    # 프로세스의 개수 (MAX = 18)\n",
    "    if numberOfThreads > 18:\n",
    "        print(bcolors.ERRMSG + \"Too much process. Check number of threads again\")\n",
    "        return\n",
    "\n",
    "    for glob in globs:\n",
    "        glob.df = measurements\n",
    "\n",
    "    # 데이터프레임을 프로세스 개수에 따라 분배하며 프로세스 개수는 성능 여유분에 따라 조절 가능합니다.\n",
    "    processes = []\n",
    "    index = 0\n",
    "    for code in tqdm(code_list, desc=\"Processing DATA\"):\n",
    "        process = mp.Process(target=starter, args=(str(code), globs[index]))\n",
    "        index = (index + 1) % numberOfThreads\n",
    "        processes.append(process)\n",
    "\n",
    "    print(bcolors.OKMSG + \"Done Successfully\" + bcolors.ENDC)\n",
    "    print(bcolors.OKMSG + \"Number of processes: \" + str(numberOfThreads) + bcolors.ENDC)\n",
    "    print(bcolors.WAITMSG + \"Analysis starts now. \" + bcolors.ITALIC +\n",
    "          \"FYI: Only stocks are included\" + bcolors.ENDC)\n",
    "\n",
    "    for i in chunks(processes, numberOfThreads):\n",
    "        for j in i:\n",
    "            j.start()\n",
    "        for j in i:\n",
    "            j.join()\n",
    "\n",
    "        # 진행상황을 체크하며 값을 확인합니다.\n",
    "        count = 0\n",
    "        for glob in globs:\n",
    "            count += glob.df.shape[0]\n",
    "        tqdm(total=len(code_list)).update(count)\n",
    "\n",
    "        # for glob in globs:\n",
    "        #     print(glob.df.tail(1), end='\\n')\n",
    "\n",
    "    merger(globs, code_list, in_path, out_path)\n",
    "\n",
    "\n",
    "# ========아래로 메인 코드입니다========= #\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "\n",
    "    measurements = pd.DataFrame(columns=(\"NAME\", \"CODE\", 'CUR PRICE', 'PREV PRICE', 'FR', \"PER\", \"EPS\",\n",
    "                                         \"E_PER\", \"E_EPS\", \"PBR\", \"BPS\", \"ITR\"))\n",
    "\n",
    "    all = [['KOSPI', 'noBank'],\n",
    "          ['KOSDAQ', 'noBank']]\n",
    "\n",
    "    ks = [['KOSPI', 'noBank']]\n",
    "\n",
    "    kp = [['KOSDAQ', 'noBank']]\n",
    "\n",
    "    test = [['TEST', 'noBank', 'all'],\n",
    "            ['TEST2', 'noBank', 'all']]\n",
    "\n",
    "    for a in ks:\n",
    "        market = a[0]\n",
    "        m_type = a[1]\n",
    "\n",
    "\n",
    "        # 12개의 데이터프레임을 만들어줍니다. 각각의 프로세서가 사용할 데이터프레임입니다.\n",
    "        manager = mp.Manager()\n",
    "        global1 = manager.Namespace()\n",
    "        global2 = manager.Namespace()\n",
    "        global3 = manager.Namespace()\n",
    "        global4 = manager.Namespace()\n",
    "        global5 = manager.Namespace()\n",
    "        global6 = manager.Namespace()\n",
    "        global7 = manager.Namespace()\n",
    "        global8 = manager.Namespace()\n",
    "        global9 = manager.Namespace()\n",
    "        global10 = manager.Namespace()\n",
    "        global11 = manager.Namespace()\n",
    "        global12 = manager.Namespace()\n",
    "\n",
    "        globs = [global1, global2, global3, global4, global5, global6,\n",
    "                 global7, global8, global9, global10, global11, global12]\n",
    "\n",
    "        '''===\n",
    "        market은 'KOSPI', 'KOSDAQ'중 하나를 선택합니다. 선택하지 않을 시 기본값은 'KOSPI'입니다.\n",
    "\n",
    "        m_type은 'noBank'(지주회사, 리츠, 은행 등 금융회사 제외), 'noUse'(noBank에서 제외된 요소만), 'ALL'(제외 없이 모두 다 포함)-\n",
    "        -중 하나를 선택합니다. 선택하지 않을 시 기본값은 'noBank'입니다.\n",
    "\n",
    "        period 는 'day'와 'week' 중 하나를 선택합니다. 'day'를 선택할 경우 가격에 관한 정보가, 'week'을 선택할 경우 투자지표에 관한 정보가 \n",
    "        수집됩니다. \n",
    "        ==='''\n",
    "\n",
    "        in_path = '/content/gdrive/My Drive/DATA/' + market + '_' + m_type + '.csv'\n",
    "        out_path = '/content/gdrive/My Drive/DATA/Results/DATA_' + market + '_' + m_type + datetime.today().strftime(\"_%Y%m%d\") + '.csv'\n",
    "        \n",
    "        code_list = get_code_list(market=market, m_type=m_type, in_path=in_path)\n",
    "\n",
    "        # 멀티 프로세스는 속도 향상을 위해 필요합니다. n개의 프로세스를 사용해 속도를 n배로 끌어 올립니다.\n",
    "        # 기본값은 8입니다.\n",
    "        multiprocess(globs, code_list=code_list, in_path=in_path, out_path=out_path, numberOfThreads=6)\n",
    "\n",
    "        initialize(globs)\n",
    "        initialize(code_list)\n",
    "\n",
    "    ex_time = time.time() - start_time\n",
    "\n",
    "    print('\\n')\n",
    "    print(bcolors.OKMSG + \"It took %dm %.2fs.\" % (ex_time / 60, round(ex_time, 2) % 60) + bcolors.ENDC)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "DATA_Crawl2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
